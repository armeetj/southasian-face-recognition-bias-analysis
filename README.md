# Bias in Industry Leading Facial Recognition Services: A Regional Analysis Across South Asian Regions
## Published Paper
Published in International Journal for Innovative Research in Interdisciplinary Fields <br>
https://www.ijirmf.com/wp-content/uploads/IJIRMF202108001.pdf
![image](https://user-images.githubusercontent.com/38377327/155048246-ee274561-ca33-46ce-b8d9-3dff28abdeb9.png)

## Author
Armeet Singh Jatyani <br>
Independent Researcher – San Jose, California, United States.<br>
Email – armeetjatyani@gmail.com<br>

## Abstract
The objective of this study is to assess the extent to which bias is present, if any, in facial
recognition services offered by FacePlusPlus, Google Cloud, and Microsoft Azure. This study assesses
the selected services across eight different South Asian regions: Kashmir (North), Ladakh (North),
Punjab (North), Rajasthan (Northwest), Jharkhand (East), Telangana (South), Tamil Nadu (Deep
South), and Gujarat (West). Our results reveal interesting and concerning patterns between
characteristics of regions, and final accuracy scores. FacePlusPlus had unevenly distributed beauty
scores, with a range of approximately 9.49, was more likely to correctly identify the gender of males,
and severely struggled to accurately detect the gender and faces of groups with heavy facial hair, such
as males in the Punjab (North) region. Microsoft Azure was more likely to accurately predict the gender
and face of females, and struggled the most (out of all three services) with groups that had heavy facial
hair, with a gender detection accuracy of just 63% for the Punjab (North) region. Finally, Google Cloud
performed phenomenally, with facial detection accuracy percentages higher than 90% across all eight
regions and genders. The results reveal disturbing biases present in the FacePlusPlus and Microsoft
Azure facial recognition/detection services, that should be addressed to maintain ethical integrity.

## Keywords
`bias, ethnic bias, regional bias, gender bias, computer vision, faceplusplus, google cloud, microsoft azure, gender classification, detection accuracy`

## Dataset
- Total: 1600 Images
- 8 Regions: 200 each (100 male, 100 female)
Samples: 
![image](https://user-images.githubusercontent.com/38377327/155048387-2847b50d-4959-4a89-be7a-3c5a2aa14a83.png)
![image](https://user-images.githubusercontent.com/38377327/155048410-c1790b7e-f4ef-4288-addc-3d2c3d97b025.png)

## Graphs
Only a few graphs are shown here. To view all results and conclusions please read the full paper: 
https://www.ijirmf.com/wp-content/uploads/IJIRMF202108001.pdf

![image](https://user-images.githubusercontent.com/38377327/155048536-a5a10939-2bdb-489c-8025-1737ef5072cb.png)
![image](https://user-images.githubusercontent.com/38377327/155048573-db5511f9-b5b3-47a9-ac3f-526203591d10.png)
![image](https://user-images.githubusercontent.com/38377327/155048592-cfba917f-945c-4a1e-a08c-fc44802d7366.png)
